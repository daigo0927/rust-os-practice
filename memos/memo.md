# フリースタンディングなRustバイナリ

## `sh_personality` Language Item

- language itemはコンパイラが内部的に必要とする特別な関数や型。`eh_personality` language itemは、スタックアンワインドを実装するための関数を定義する。

## リンカエラー

- リンカはコードを実行可能ファイルに紐つけるプログラム。デフォルトの設定では、リンカはCランタイムの起動ルーチンを含んでいる。今回はベアメタル環境での実行を実施するため、Cランタイムへの依存は回避したい。

---

# Rustで作る最小のカーネル

## 起動（Boot）のプロセス

コンピュータを起動すると、マザーボードのROMに保存されたファームウェアのコードが実行される。このコードはRAMの検出やCPUなどハードウェアの初期化し、その後ブート可能ディスクを探す。ファームウェアの規格にはBIOSとUEFIがある。

ディスクが見つかると、ブートローダーと呼ばれる先頭512バイトに保存された実行可能コードへと操作権が移る。ブートローダーはディスク内のカーネルイメージの場所を特定し、メモリに読み込む。またCPUを64bitのロングモードに変更し、64bitレジスタと全てのメインメモリを利用可能にする。そしてメモリーマップなどの特定の情報をBIOSから聞き出し、OSのカーネルに渡す。

### Multiboot標準規格

- カーネル：OSの中核となるソフトウェア。プログラムの実行管理や、ハードウェアへのアクセス提供などを行う。
- Linuxで人気のブートローダーとしては、GNU GRUBなどがある。
- ブートローダーの標準規格として、フリーソフトウェア財団がMultibootと言う規格を策定している。

## 最小のカーネル

- SIMD(Single Instruction Mutiple Data)：コンピュータやプロセッサで並列処理を行うための設計様式の一つ。プログラムを高速化してくれる場面が多いが、OSカーネル上で使うと性能への悪影響がありえるので、今回は無効化する。

### 画面に出力する

`unsafe`ブロックはRustでのプログラミング時にはできるだけ避けたい。このためには、Rustでは安全なabstractionを作ることができる。これにunsafeな操作をカプセル化することで、外部からの誤った操作を防ぐことができる。

## カーネルを実行する

### ブートイメージを作る

`bootimage`ツールによって、`bootloader`クレートをスタンドアロンの実行ファイルとしてコンパイルし、カーネルのELFファイルのバイト列をブートローダーにリンクする。

起動時には、ブートローダーは追加されたELFファイルを読み込み、解釈する。次にプログラムをページテーブルの仮装アドレスにマップし、`.bss`部をゼロにし、スタックをセットアップする。最後にエントリポイントのアドレス（`_start`関数）を読み、そこにジャンプする。

---

# VGAテキストモード

## Rustのモジュール

### テキストバッファ

VGAバッファへの参照は`buffer`に格納される。この参照がどのくらい有効かをコンパイラに伝えるために、明示的なライフタイムが必要になる。`'static`ライフタイムは、その参照がプログラムの実行中ずっと有効であることを指定している。

```rust
// in src/vga_buffer.rs

pub struct Writer {
    column_position: usize,
    color_code: ColorCode,
    buffer: &'static mut Buffer,
}
```

### Volatile

- volatileな書き込み：この書き込みに副作用があること。今回は最適化により取り除かれるべきでは無いとコンパイラに命令する必要があるため、`volatile`ライブラリ（クレート）を使う。`volatile::Volatile`というラッパー型は`read, write`というメソッドを提供しており、読み込み・書き込みが最適化により取り除かれないことを保証する。

## 大域的（global）なインターフェース

### Lazyな静的変数

定数でない関数で一度だけ静的変数を初期化したい場合がある。こうした時は`lazy_static`クレートを用いることで、初期化が後回しにされる`static`を定義する、`lazy_static!`マクロを提供する。これによって静的な`WRITER`を問題なく定義できる。

### スピンロック

同期された内部か変性を得るためには、標準ライブラリを使えるならMutexクレートが使える。これはリソースがすでにロックされていた場合、スレッドブロックによって相互排他性を提供する。

今回作るカーネルにはブロックやスレッドの概念がないので、OSを必要としない単純なmutexとして、スピンロックを用いる。スピンロックを用いることで、ブロックする代わりにリソースを何度もロックしようとする。これによってmutexが解放されるまでの間CPU時間を使い尽くす。

---

# テスト

## コンソールに出力する

### タイムアウト

`cargo test`はテストランナーが終了するまで待つので、終了しないテストがあるとテストランナーを永遠にブロックしかねない。今回は以下のようなケースで無限ループが発生し得る。

- ブートローダーがカーネル読み込みに失敗し、システムが再起動し続ける
- BIOS/UEFIファームウェアがブートローダーの読み込みに失敗し、再起動し続ける
- 作った関数のどれかの最後で、CPUが`loop {}`文に入ってしまう（例えばQEMU終了デバイスがうまく動かなかったなどの理由）
- CPU例外がうまく捕捉されなかった場合などに、ハードウェアがシステムリセットを行う

これに対して、今回使っている`bootimage`クレートは標準で5分のタイムアウトを設定している。テストがこの時間内に終了しなかった場合は失敗とみなされ、"Timed Out"エラーがコンソールに表示される。

## 結合テスト

### ライブラリを作る

結合テストに必要な関数を利用するために、`main.rs`から必要なライブラリを`src/lib.rs`として分離する。`lib.rs`は`main.rs`と同様に、cargoから認識される特別なファイルである。`cargo test`コマンドからもライブラリを使うため、テストのための関数や属性を`main.rs`から`lib.rs`へ移した。

---

# CPU例外

## 概要

例外は実行している命令が異常であることを示す。例えばゼロ除算を実行しようとしている時、CPUは例外を発する。例外が起こると、CPUは現在行われている作業に割り込み、例外の種類によって特定の例外ハンドラ関数を呼ぶ。

x86には20種類のCPU例外があり、重要なものとしては以下がある。

- ページフォルト：不正なメモリアクセス時に発生。読み込み専用ページへの書き込みなど
- 無効な命令コード：旧式CPUで、サポートしていない新しい命令を実行しようとした時など
- 一般保護違反：いろいろな種類のアクセス違反で発生
- ダブルフォルト：何らかの例外が起き、CPUガレ以外ハンドラを呼び出しているときに別の例外が起こった場合に発生
- トリプルフォルト：CPUがダブルフォルトのハンドラ関数を呼び出そうとしている間に、さらに例外が起こった場合に発生。トリプルフォルトを捕捉したり処理することはできず、多くのプロセッサは自らをリセットしてOS再起動を実行する。

### 割り込み呼び出し規約

例外を捕捉し処理するためには、割り込み記述子表（IDT：Interrupt Descriptor Table）を設定する必要がある。ハードウェアはこの表を直接使うので、決められたフォーマットに従う必要がある。

例外発生時に、CPUはざっくり以下を行う。

1. 命令ポインタとRFLAGSレジすらを含むレジスタをスタックにプッシュする
2. 割り込み記述子表から対応するエントリをよみ、例えば、ページフォルトが起こったときはCPUは十四番目のエントリを読む
3. エントリが存在しているかチェックする。そうでなければダブルフォルトを起こす
4. エントリが割り込みゲート（40番目のビットがゼロ）ならハードウェア割り込みを無効にする
5. 指定されたGDT（大域記述子表）セレクタをCSセグメントに読み込む
6. 指定されたハンドラ関数にジャンプする

## 例外の呼び出し規約

例外と関数呼び出しは似ている。CPUが呼び出された関数の最初の命令にジャンプし、それを実行する。その後CPUはリターンアドレスにジャンプし、親関数の実行を続ける。

一方で、例外と関数呼び出しの大きな違いとして、例外はどんな命令の実行中でも起こる可能性がある。

呼び出し規約は、関数呼び出しについて細かく指定している。例えば関数のパラメータがどこ（スタック、レジスタ、など）に置かれるべきか、結果がどのように返されるべきか、などを指定している。

### PreservedレジスタとScratchレジスタ

呼び出し規約はレジスタをpreserved（保存）レジスタとscratch（下書き）レジスタの2種類に分けている。preservedレジスタは関数呼び出しの前後で変化してはいけない。対してscratchレジスタは呼び出された関数から、何の制約もなく上書きできる。

x86_64においては、C言語の呼び出し規約は以下のpreserved, scratchレジスタを指定する。

| **preservedレジスタ** | **scratchレジスタ** |
|:-:|:-:|
| `rbp, rbx, rsp, r12, r13, r14, r15` | `rax, rcx, rdx, rsi, rdi, r8, r9, r10, r11` |
| *callee-saved*  | *caller-saved*  |

コンパイラはこれらのルールを知っているため、それに従ってコードを生成する。

一方で、例外はどんな命令の最中にも起きる可能性がある。多くの場合、生成されたコードが例外を引き起こすのかどうかは、コンパイル時には検討もつかない。よってレジスタを事前にバックアップしておくことは不可能となる。代わりに全てのレジスタを保存する規約を使う必要がある。

`x86-interrupt`呼び出し規約はそのような呼び出し規約なので、関数が戻るときに全てのレジスタが元の値に戻されることを保証してくれる。複雑な例外処理プロセスを隠蔽してくれる、強力な抽象化と言える。

---

# Double Faults

## ダブルフォルトの原因

AMD64のマニュアルでは、ダブルフォルト例外の正確な定義として「ダブルフォルト例外は直前の（1度目）の例外ハンドラの処理中に2度目の例外が発生したとき起きうる」と書かれている。「起き得る」というのが重要で、実際には特別な例外の組み合わせでのみダブルフォルトとなる。

### カーネルスタックオーバーフロー

カーネルがスタックをオーバーフローさせて、ガードページにヒットした場合を考える。

ガードページはスタックの底にある特別なメモリページで、これによってスタックオーバーフローを検出できる。このページはどの物理メモリにもマップされていないので、アクセスしようとするとページフォルトが発生する。

ページフォルトが起きると、CPUはIDT内のページフォルトハンドラを探しに行き、割り込みスタックフレームをスタックにプッシュしようとする。しかし、このスタックポインタは存在しないガードページを指しているため、結果として2度目のページフォルトが発生し、ダブルフォルトとなる。

ここでCPUはダブルフォルトハンドラを呼びに行くが、ダブルフォルト例外においてもCPUは例外スタックフレームをプッシュしようと試みる。スタックポインタはまだガードページを指しているので、3度目のページフォルトが起き、トリプルフォルトとなる。結果としてシステムは再起動となる。

これに対処するには、ダブルフォルト例外が発生したとき、スタックが常に正常であることをどうにかして保証する必要がある。x86_64アーキテクチャは、スタックを切り替えることでこの問題に対応する。

## スタックを切り替える

x86_64アーキテクチャは例外発生時にあらかじめ定義されている基地の正常なスタックに切り替えることができる。この切り替えはハードウェアレベルで発生するので、CPUが例外スタックフレームをプッシュする前に行うことができる。

切り替えの仕組みは割り込みスタックテーブル（IST：Interrupt Stack Table）として実装されている。ISTは7つの基地の正常なポインタのテーブルであり、Rustの疑似コードで表すと以下のようになる。

```rust
struct InterruptStackTable {
    stack_pointers: [Option<StackPointer>; 7],
}
```

CPUがダブルフォルト起こした際には必ずこのスタックに自動的に切り替えを行う。この切り替えは何かがプッシュする前に起きるので、トリプルフォルトを防ぐことができる。

### ISTとTSS

割り込みスタックテーブル（IST）は、タスクステートセグメント（TSS）というレガシーな構造体の一部である。x86_64においてはTSSはタスク固有の情報は持たなくなり、代わりに2つのスタックテーブル（一つがIST）を持つようになった。

### グローバルディスクリプタテーブル

TSSを作ったので、CPUにそれを使うために教える方法が必要となる。TSSはセグメンテーションシステムを使うため、テーブルを直接読み込むのではなく、新しいセグメントディスクリプタをグローバルディスクリプタテーブル（GDT）に追加する必要がある。

- IDT（Interrupt Descriptor Table）：割り込みと割り込みハンドラ（対応する処理）を結びつけるテーブル
- IST（Interrupt Stack Table）：例外発生時に用いるための、既知の正常なスタックへのポインタ
- TSS（Task State Segment）：ISTを保持する構造体。他に特権スタックテーブルやI/Oマップベースアドレスも保持する。
- GDT（Global Descriptor Table）：メモリセグメンテーションのための仕組み。ページングがデファクトスタンダードになる前に使われていた。今でもカーネル・ユーザーモードの設定やTSSの読み込みなどを行うために必要。

---

# ハードウェア割り込み

## 概要

割り込みは、接続されたハードウェアデバイスからCPUに通知する方法を提供する。同様に、よって、例えばキーボードは各キーが押されたことをカーネルに通知できる。

全てのハードウェアデバイスをCPUに直接接続することはできないので、代わりに別の割り込みコントローラーが全てのデバイスからの割り込みを集約してからCPUに通知する。

```
                                    ____________             _____
               Timer ------------> |            |           |     |
               Keyboard ---------> | Interrupt  |---------> | CPU |
               Other Hardware ---> | Controller |           |_____|
               Etc. -------------> |____________|
```

## 8259 PIC

Intel 8259は、1976年に導入された、プログラム可能割り込みコントローラー（PIC）である。現在は新しいAPICがあるものの、下位互換性のために現在のシステムでもインターフェイスがサポートされている。

8259にはCPUと通信するための8本の割り込みラインと、その他複数のラインがある。当時の一般的なシステムには8259 PICの二つのインスタンスが装備されており、一つはプライマリPICで、もう一つはプライマリPICの割り込みラインの一つに接続されたセカンダリPICである。

```
                     ____________                          ____________
Real Time Clock --> |            |   Timer -------------> |            |
ACPI -------------> |            |   Keyboard-----------> |            |      _____
Available --------> | Secondary  |----------------------> | Primary    |     |     |
Available --------> | Interrupt  |   Serial Port 2 -----> | Interrupt  |---> | CPU |
Mouse ------------> | Controller |   Serial Port 1 -----> | Controller |     |_____|
Co-Processor -----> |            |   Parallel Port 2/3 -> |            |
Primary ATA ------> |            |   Floppy disk -------> |            |
Secondary ATA ----> |____________|   Parallel Port 1----> |____________|
```

各コントローラーは、二つのI/Oポート、一つのコマンドポートと一つのデータポートを介して構成できる。今回は`pic8259`クレートの`ChainedPics`を用いることで、上記のプライマリ/セカンダリPICレイアウトを構成する。

## キーボード入力

ハードウェアタイマーと同時に、キーボードコントローラーはデフォルトで有効になっている。
キーを押すとキーボードコントローラーはPICに割り込みを送信し、PICはそれをCPUに転送する。CPUはIDTでハンドラ関数を探すが、対応するエントリが空なため、現時点ではダブルフォルトとなる。よってキーボード割り込みのためのハンドラ関数が必要となる。

キーボード割り込みのハンドラ関数を実装すると、キーを押したタイミングで画面に「k」と表示される。ただし最初に押したキーのみに反応している。これは押されたキーのスキャンコードを読み取るまで、キーボードコントローラーが別の割り込みを送信しないためである。

### スキャンコードを読む

どのキーが押されたかを確認するには、キーボードコントローラに問い合わせる必要がある。PS/2コントローラのデータポート、今回は`0x60`番のI/Oポートからバイト（スキャンコード）を読み取ることで、これを行う。

### スキャンコードの解釈

スキャンコードはキーを押したタイミングと話したタイミングそれぞれに存在する。キーを表示するには、スキャンコードとキーのマッピングを把握する必要があり、これにはスキャンコードセットと呼ばれる3つの標準がある。

今回は`pc-keyboard`クレートを用いて、スキャンコードを翻訳する。

---

# ページング入門

## メモリの保護

オペレーティングシステムの主な役割の一つに、プログラムを違いに分離するということがある。例えば、ウェブブラウザがテキストエディタに干渉してはいけない。この目的のために、オペレーティングシステムはハードウェアの機能を利用して、あるプロセスのメモリ領域に他のプロセスがアクセスできないようにする。

x86_64アーキテクチャでは、ハードウェアは2つの異なるメモリ保護の方法をサポートしている。セグメンテーションとページングである。

## セグメンテーション

セグメンテーションは1978年にはすでに導入されており、当初の目的はアドレス可能なメモリ量を増やすことだった。セグメントレジスタが追加され、それぞれにオフセットアドレスを格納することで、CPUがメモリにアクセスするときに、広い範囲のメモリアドレスを扱えるようになった。

のちにプロテクトモードが導入されると、セグメントレジスタにはオフセットアドレスに加えて、セグメントのサイズとアクセス権限が可k農されるようになった。それぞれのプロセスに対してメモリアクセスをプロセスのメモリ領域のみに制限する（ような大域/局所ディスクリプタテーブル）をロードすることで、OSはプロセスを互いに分離出来るようになった。

メモリアドレスを実際にアクセスされる前に変更するという点において、セグメンテーションは仮想メモリのテクニックをすでに採用していたと言える。

### メモリ断片化（fragmentation）

物理アドレスと仮想アドレスを分けることで、セグメンテーションは強力なものとなった。一方で、物理上のメモリ領域が細切れになってしまう、メモリ断片化という問題が起きるようになった。

これにはプログラムを一時停止し、使用中のメモリ領域を整理して物理的に連続した空きメモリ領域を確保するデフラグ面テーションという処理で対応できるが、大量のメモリコピーが必要であり、パフォーマンスが低下してしまう。

実際、x86の64ビットモードではセグメンテーションはサポートされなくなり、ページングが使用されるようになった。これによって断片化の問題は完全に回避されるようになった。

## ページング

ページングの考え方は、仮想メモリ空間と物理メモリ空間の両方を、サイズの固定された小さなブロックに分割するというものである。仮想メモリ空間のブロックはページと呼ばれ、物理アドレス空間のブロックはフレームと呼ばれる。各ページはフレームに独立してマッピングできるので、大きなメモリ領域を連続していない物理フレームに分割することができる。

### 隠された断片化

少ない数の可変サイズのメモリ領域をつかていたセグメンテーションに対して、ページングでは大量の小さい固定サイズのメモリ領域を使う。このとき厳密にはメモリ断片化は起こっているものの、デフラグメンテーションする必要がなく断片化の量も予想できるため、セグメンテーションにおける断片化（外部断片化）に対して優れている。

### ページテーブル

最大で数百万のページを、それぞれ独立にフレームに対応づけるため、この対応関係をどこかに保存する必要がある。セグメンテーションでは、有効なメモリ領域ごとに個別のセグメントセレクタを使っていたが、ページングではレジスタよりも遥かに奥のページが使われるためこれは不可能となる。
代わりにページングでは、ページテーブルという表構造を使って対応関係の情報を保存する。

ページテーブルのカラムには仮想メモリ、対応するフレーム、（アーキテクチャによっては）アクセス権限などのフラグなどがある。

### 複数層（Multilevel）ページテーブル

1層からなるページテーブルは、アドレス空間が大きくなってくると無駄なエントリが発生し、必要以上にテーブルが大きくなってしまうという問題がある。これに対して、それぞれのアドレス領域に異なるページテーブルを使い、ページテーブルを多層化することができる。このとき対応付けのないメモリ領域のためのレベル１テーブルを作る必要がなくなり、ページテーブルを効率的に保持することができる。

## x86_64におけるページング

x86_64アーキテクチャでは4層ページテーブルを使っており、ページサイズは4KiBである。それぞれのページテーブルは層によらず512のエントリを持っている。それぞれのエントリの大きさは8バイトなので、各テーブルは512×8B=4KiBとなり、ぴったり1ページに収まる。

### ページテーブルの形式

x86_64アーキテクチャにおけるページテーブルは、詰まるところ512個のエントリの配列と言える。

```rust
#[repr(align(4096))]
pub struct PageTable {
    entries: [PageTableEntry; 512],
}
```

Rustの構文では上記で表される。`repr`属性より、ページテーブルがアラインされ、ページ一つを完全に使うため、エントリをコンパクトに保持する最適化が可能になる。

それぞれのエントリは8バイト（64ビット）の大きさであり、以下の情報を保持する。

| ビット | 名前 | 意味 |
|:--|:--|:--|
| 0 | present | このページはメモリ内にある |
| 1 | writable | このページへの書き込みは許可されている |
| 2 | user accessible | 0の場合、カーネルモードのみこのページにアクセスできる |
| 3 | write through caching | 書き込みはメモリに対して直接行われる |
| 4 | disable cache | このページにキャッシュを使わない |
| 5 | accessed | このページが使われているとき、CPUはこのビットを1にする |
| 6 | dirty | このページへの書き込みが行われたとき、CPUはこのビットを1にする |
| 7 | huge page/null | P1とP4においては0で、P3においては1GiBのページを、P2においては2MiBのページを作る |
| 8 | global | キャッシュにあるこのページはアドレス空間変更の際に初期化されない（CR4レジスタのPGEビットが1である必要がある） |
| 9-11 | available | OSが自由に使える |
| 12-51 | physical address | ページ単位にアラインされた、フレーム又は次のページテーブルの52bit物理アドレス |
| 52-62 | available | OSが自由に使える |
| 63 | no execute | このページにおいてプログラムを実行することを禁じる（EFERレジスタのNXEビットが1である必要がある） |

今回は`x86_64`クレートがページテーブルとそのエントリのための型を提供しているので、これらの構造体をゼロから作る必要はない。

## 実装

これまでに作ったカーネルでは、すでにページングは実装されている。現在利用しているブートローダは、すでにこれまで製作したカーネルの全てのページを物理フレームに対応づけるような4ページ階層構造を設定している。

つまり、これまでカーネルで使ってきた全てのメモリアドレスは仮想アドレスだった。アドレス`0xb8000`にあるVGAバッファへのアクセスが美味くっていたのは、ブートローダがこのメモリページを口頭対応させていた、つまり仮想ページ`0xb8000`を物理フレーム`0xb8000`に対応させていたからである。

### ページテーブルへのアクセス

`x86_64`クレートの`Cr3::read`関数は、現在有効なレベル4ページテーブルを`CR3`レジスタから読み取って返す。これによってレベル4ページテーブルを確認することができる。

このテーブルに、製作したカーネルからアクセスできるかを考える。ページングが有効なとき、物理メモリに直接アクセスすることはできない。仮にできたとすると、プログラムがメモリ保護を回避して他のプログラムのメモリにアクセスできてしまうからである。

なので、テーブルにアクセスする唯一の方法は、アドレスの物理フレームに対応づけられている仮想ページにアクセスすることとなる。ページテーブルの存在するフレームへの対応付けは、実用上も必要な一般的な問題である。例えば、新しいスレッドのためにスタックを割り当てるときなど、カーネルは日常的にページテーブルにアクセスする必要がある。

---

# ページングの実装

## ブートローダによる補助・実装

ブート情報を使うフレームアロケータのおかげで、未使用のページをマッピングすることができた。背後では、`map_to`メソッドが不足しているページテーブルを以下の方法で作成している。

- 渡された`frame_allocator`を使って未使用のフレームを割り当ててもらう
- フレームをゼロで埋めることで、新しい空のページテーブルを作る
- 上位のテーブルのエントリをそのフレームにマップする
- 次の層で同じことを続ける

## まとめ

ページテーブルのある物理フレームにアクセスするためのテクニックとして、恒等マップ、物理メモリ全体のマッピング、一時的なマッピング、再帰的ページテーブルなどを学んだ。この中で、特にシンプルでポータブル（アーキテクチャ非依存）で強力な、物理メモリ全体のマッピングを選んだ。

ページテーブルにアクセスできなければ物理メモリをマップされないので、ブートローダの補助が必要だった。`bootloader`クレートはcargoのfeaturesオプションを通じて、必要となるマッピングの作成をサポートしている。さらに、必要となる情報をエントリポイント関数の`&BootInfo`引数という形で、今回のカーネルに渡してくれる。

実装については、はじめにページテーブルをたどる変換関数を自分の手で実装し、その後`x86_64`クレートの`MappedPageTable`型を使った。又、ページテーブルに新しいマッピングを作る方法や、そのために必要な`FrameAllocator`をブートローダに渡されたメモリマップをラップすることで作る方法を学んだ。

---

# ヒープ割り当て

## ローカル変数と静的変数

現在、カーネルではローカル変数と`static`変数の2種類の変数を使用している。ローカル変数は呼び出しスタックに格納され、関数が戻るまでのみ有効となる。せち的変数は固定メモリに保存され、プログラムの動作中常に存続する。

## ローカル変数

Rustコンパイラは、各変数の有効期間を強制し、これを超えようとした場合、例えばローカル変数への参照を返そうとした場合などにエラーを返す。

```rust
fn inner(i: usize) -> &'static u32 {
    let z = [1, 2, 3];
    &z[i]
}
```

上記は冗長な例であるものの、変数を函数よりも長く存続させたい場合はある。これまでだと、割り込み記述子表（IDT）をロードしようとしたとき、カーネルでこのようなケースが発生しており、有効期間を延長するために`static`変数を使用していた。

### 静的変数

静的変数はスタックとは別の固定メモリ位置に格納される。このメモリ位置はコンパイル時にリンカによって割り当てられ、実行可能ファイルにエンコードされる。静的変数はプログラムの実行中ずっと存続するため、ローカル変数から常に参照することができる。

## ダイナミックメモリ

ローカル変数と静的変数はすでに多くのユースケースに対応できるものの、どちらにも制限がある。

- ローカル変数は、関数又はブロックが終了するまでしか存続しない。これは、それらが呼び出しスタックに存在し、周囲の関数が戻った後に破棄されるためである。
- 静的変数は、プログラムの実行中常に存続するため、不要になった時にメモリを再利用する方法がない。また所有権のセマンティクスが不明瞭、全ての関数からアクセスできるため、変更する場合は`Mutex`で保護する必要がある。

ローカル変数と静的変数のもう一つの制限は、サイズが固定されていることである。よって、要素が追加された時に銅的に増加するコレクションを保持できない。これを回避するために、プログラミング言語はヒープと呼ばれる、変数を格納するための3番目のメモリ領域をサポートしていることが多い。

ヒープは`allocate, deallocate`という二つの関数によって、ランタイム中の銅的メモリ割り当てをサポートしている。`allocate`関数は特定サイズのフリーなメモリを返し、これに変数を格納しておくことができる。この変数は`deallocate`関数が呼ばれるまで存続することができる。

`allocate`された変数は、`deallocate`によって適切にメモリを解放しないとメモリリークに繋がり、過剰なメモリ消費を招く恐れがある。

### 一般的なエラー

メモリリークは問題であるものの、攻撃者に対するプログラムの脆弱性にはつながらない。一方で、下記の一般的なバグはもっと深刻と言える。

- `deallocate`を呼び出した後に誤って変数を使い続けると、解放後仕様の脆弱性が発生する。このバグは未定義動作を引き起こし、攻撃者が任意のコードを実行するために悪用される恐れがある。
- 誤って変数を二回解放すると、二重解放の脆弱性が発生する。これは最初の呼び出し後に同じ場所に割り当てられた別の割り当てを解放する可能性があり、解放後仕様の脆弱性が再び発生する可能性がある。

これらの問題を回避するために、JavaやPythonなどの言語ではガベージコレクションによって動的メモリが自動的に管理され、プログラマが手動で`deallocate`を呼び出すことはない。プログラムは定期的に一時停止され、未使用のヒープ変数がないかスキャンされ、自動的に割り当てが解除される。欠点としてはスキャンによるオーバーヘッドと、停止時間となる。

Rustはこれと異なり、所有権というアプローチを採用しており、動的メモリ操作の正当性をコンパイル時にチェックしている。これによってガベージコレクションは必要なくなり、パフォーマンスのオーバーヘッドを無くすことができる。別のメリットとして、プログラマはC, C++のように動的メモリに対する細かい操作も可能となっている。

### ユースケース

動的メモリ割り当ては、割り当てごとにヒープ上に空きスロットを見つける必要があるため、常にパフォーマンスのオーバーヘッドが少しある。よって、特にパフォーマンスに敏感なカーネルコードでは、ローカル変数が一般的に推奨される。

動的メモリ割り当てが適したユースケースを考える。原則として、動的なライフタイムや変数サイズを持つ変数には動的メモリが必要となる。動的な有効期間を持つ最も重要なタイプとしては`Rc`がある。これはラップされた値への参照をカウントし、全ての参照がスコープ街になった後に割り当てを解除する。

可変サイズのタイプの例は`Vec, String`その他のコレクションタイプがある。これらのタイプは、一杯になるとさらに大きなメモリを割り当て、全ての要素をコピーし、再割り当てを行う。

将来的なカーネルでは、マルチタスクを実装する際にアクティブなタスクのリストを保持するためにコレクション型が必要になると思われる。

## アロケータクレートの使用

アロケータの実装はやや複雑なので、まずは既存のアロケータクレートを使用する。`no_std`アプリケーション用のシンプルなアロケータクレートとしては`linked_list_allocator`クレートがある。これは名前の通り、結合リストデータ構造を使用して、割り当て解除されたメモリ領域を追跡する。

`alloc`クレートには、以下のようなアロケーションやコレクション型がある。

- スレッド安全な参照カウントポインタ`Arc`
- 文字列型`String`と`format!`マクロ
- `LinkedList`
- 伸長可能なリングバッファ`VecDeque`
- `BinaryHeap`
- `BTreeMap, BTreeSet`

---

# アロケータのデザイン

ここでは、ヒープアロケータを最初から実装する方法を考える。バンプ割り当て、結合リスト割り当て、固定サイズのブロック割り当てなど、色々なアロケータの設計を検討する。

## 序章

### 設計目標

アロケータの責任は、使用可能なヒープメモリを管理することである。`alloc`呼び出し時に未使用のメモリを返し、`dealloc`で解放されたメモリを追跡して、再利用できるようにする必要がある。最も重要なのは、他の場所ですでに使用されているメモリを配布しないことである（未定義動作に繋がる恐れがある）。

アロケータには多くの二次的な設計目標がある。例えば、アロケータは利用可能なメモリを効果的に利用し、断片化を低く抑える必要がある。また並行アプリケーションでうまく機能し、任意の数のプロセッサに拡張できた方が良い。パフォーマンスを最大化するためには、CPUキャッシュに関してメモリレイアウトを最適化して、キャッシュの局所性を改善し、誤った共有を回避することもできる。

## バンプアロケータ（スタックアロケータ）

バンプアロケータは最も単純なアロケータの設計である。メモリを線形に割り当て、割り当てられたバイト数と割り当て数のみを追跡する。一度に全てのメモリを解放する必要があるという厳しい制約のため、特殊なユースケースでのみ役に立つ。

### ディスカッション

バンプアロケータの大きな利点は、非常に高速なことである。適切なメモリブロックを積極的に探す他のアロケータ設計と比べて、バンプアロケータはわずかなアセンブル手順に最適化できる。これによって仮想DOMライブラリを作成する場合などに役に立つ。

一方で欠点としては、全ての割り当てが解放された後にのみ、メモリを再利用できるという点である。

## 結合リストアロケータ

アロケータにおいて任意の数のフリーメモリ領域を追跡するための一般的なテクニックは、その領域自体をバッキングストレージとして利用することである。解放された領域に関する情報を領域自体に格納することで、追加のメモリを必要とせずに、解放された領域を無制限に追跡できるようになる。

一般的な実装方針としては、解放されたメモリに単一の結合リストを作成し、各ノードを解放されたメモリ領域とすることである。各ノードはメモリ領域のサイズと、次の未使用メモリ領域へのポインタの二つのフィールドを持つ。これによって、初めの未使用メモリのポインタから、全体の未使用メモリを追跡することができる。このデータ構造はフリーリストとも呼ばれる。これは`linked_list_allocator`クレートが利用している方法でもある。

### ディスカッション

バンプアロケータに対して、結合リストアロケータは広く一般的な用途に適している。これは主にフリーメモリを直接再利用できるためである。

一方で問題もある。一つは、少なくとも今回の実装においては一度分割されたヒープが解放された後もマージされないことである。
`linked_list_allocator`クレートはマージ処理も実装している。このクレートでは、`deallocate`で解放されたメモリブロックを結合リストの先頭に挿入する代わりに、常にリストを開始アドレス順にソートして保持する。そして`deallocate`の際にリストを走査し、隣接するブロックをマージする。これによって`deallocate`の処理は遅くなるが、ヒープ断片化を防ぐことができる。

結合リストアロケータにおけるメモリ割り当ては、メモリ領域に要求の度にリストを走査するため、プログラムの種類によってパフォーマンスが大きく変化する。メモリ割り当てが多く、ヒープが多く分割されるようなプログラムでは、パフォーマンスが大きく劣化する。これは実装レベルではなく、結合リストを用いることに起因している。

カーネルレベルのコードではアロケーションパフォーマンスが非常に重要になるため、パフォーマンスを向上したアロケー田設計を考える。

## 固定サイズブロックアロケータ

固定ブロックアロケータでは、メモリ割り当て要求に対して固定サイズのメモリブロックを割り当てる。必要なメモリ量よりも大きいブロックを返し得るため、内部断片化が発生する。一方で、結合リストアロケータに比べて非常に速く適切なメモリブロックを探すことができ、優れたアロケータパフォーマンスとなる。

### 紹介

固定サイズブロックアロケータでは、いくつかのブロックサイズを定義する。例えば16, 64, 512バイトのブロックサイズを用いたとすると、4バイトの割り当てには16バイトのブロックを、48バイトの割り当てには64バイトのブロックを割り当てる。

結合リストアロケータと同様に、ここでも結合リストを用いて未使用メモリを管理する。しかし、単一の結合リストではなくブロックサイズごとに個別の結合リストを用いる。よって、`head`ポインタについても`head_16, head_64, head_512`を保持する。各ポインタは同じサイズのブロックのみを保持するため、リストの各ノードでサイズを保持する必要はなくなる。

一つのリスト内の要素はどれも同じサイズのため、メモリ割り当ては下記のように非常に効率的に行うことができる。

1. 要求されたメモリサイズを切り上げ、適切なブロックサイズを計算する
2. 対応する先頭ポインタを検索する（`head_16`など）
3. 先頭のブロックを削除し、返す。

返すべきメモリブロックは常に先頭にあるため、割り当て要求のためにリストを走査する必要がなく、高速に割り当てを行うことができる。

#### ブロックサイズと無駄なメモリ

使用するブロックサイズによっては、切り上げによって無駄なメモリが発生する。例えば各ブロックサイズを2の累乗にすることで、メモリの無駄を最大でも割り当てサイズの半分、平均的には4分の1に抑えることができる。

#### 割り当て解放

割り当て時と同様に、解放も高速に行うことができる。結合リストの走査が不要なため、リストの長さによらない時間で`dealloc`の処理を行うことができる。

1. 解放された割り当てサイズを切り上げ、対応するブロックサイズを算出する
2. 対応する先頭ポインタを得る
3. 先頭ポインタを更新し、解放されたブロックをリストの先頭に追加する

#### 新しいブロックの作成

場合によっては、特定のブロックサイズのリストが空になってしまう（割り当てができない）可能性がある。こうしたときは二つの方法によって、新しい特定サイズの未使用ブロックを作成し、割り当て要求に対応することができる。

- フォールバックアロケータから新しいブロックを割り当てる
- 大きいブロックサイズのリストからブロックを分割する。これはブロックサイズが2の累乗の時に最適と言える。

ここではフォールバックアロケータを用いる、シンプルなパターンを実装する。

### ディスカッション

固定サイズブロックアロケータはOSカーネルのようなパフォーマンスが重要なケースでは、ベターな選択と言える。

固定サイズブロックアロケータには、多くの種類がある。有名な物としては**slab allocator**と**buddy allocator**の2つがあり、Linuxなどのポピュラーなカーネルで使われている。

slab allocatorはカーネルで選ばれた型に対応したブロックサイズを直接利用するというものである。これによって、必要な型に対してちょうどのサイズのブロックを割り当てることができ、メモリの無駄がなくなる。

buddy allocatorは、解放されたブロックを管理するために、連結リストではなく二分木を用いる。特定サイズの新しいブロックが要求された際には、大きいサイズのブロックを半分に分割し、二つの子ノードとする。ブロックが解放されると、木における近傍ブロックが解析され、フリーな近傍ブロック同士をマージする。これによって小さい解放済みブロックを大きい割り当てに再利用でき、外部断片化を抑えることができる。

--- 

# Async/Await

## マルチタスク

ほとんどのOSの基本機能の一つに、複数のタスクを同時実行するマルチタスクというものがある。例えば、ブラウザを見ながらテキストエディタやターミナルウィンドウを開いていたり、他にも様々なバックグラウンドタスクがあり得る。

一見全てのタスクが並行して実行されているように見えても、一つのCPUコアで同時に実行できるのは一つのタスクだけである。OSは実行中のタスクを素早く切り替えることで、それぞれのタスクが少しずつ進むようにしている。

マルチタスクには二つの形態がある。協調的マルチタスクでは、タスクが定期的にCPUの制御を放棄することで、他のタスクの処理を進める。非協調的マルチタスクは、OSの機能を利用して、任意の時点でスレッドを強制的に一時停止させて切り替える。以下ではこの二つのマルチタスクについて長所と短所を説明する。

### 非協調的マルチタスク

非協調的マルチタスクでは、タスクを切り替えるタイミングをOSが管理する。このために、割り込みのたびにCPUの制御権がOS側に戻ってくることを利用する。これによって、マウスを動かしたりネットワークパケットが届いたときなど、システムに新しい入力があった時にタスクを切り替えることができる。

#### 状態の保存

タスクは任意の状態で中断されるため、計算の途中である可能性もある。後で再開できるようにするためには、OSはタスクのコールスタックや全てのCPUレジスタなど、タスクの状態全体をバックアップする必要がある。この作業をコンテキストスイッチという。

各タスクのコールスタックは非常に大きくなる可能性があるため、OSは通常各タスクのスイッチでコールスタックの内容をバックアップする代わりに、各タスクに個別のコールスタックを設定する。このような独立したスタックを持つタスクは、_thread of execution_と呼ばれる。タスクごとに独立したスタックを使用することで、コンテキストスイッチの際に保存する必要があるのはレジスタの内容（プログラムカウンタとスタックポインタを含む）だけになる。これによって、コンテキストスイッチの性能上のオーバーヘッドが最小限になる。

#### 議論

非協調的マルチタスクの主な利点は、OSがタスクの許容実行時間を完全に制御できることである。これいよって、各タスクが協力しなくても、CPU時間を公平に確保できることが保証される。これはサードパーティのタスクを実行する場合や、複数のユーザーがシステムを共有する場合に特に重要となる。

非協調的マルチタスクの欠点は、各タスクが独自のスタックを必要とすることである。共有スタックと比べると、タスクごとにメモリ使用量が多くなり、システム内のタスク数が制限されることが多くなる。また、タスクがレジスタのごく一部しか使用していない場合でも、タスクが切り替わるたびにOSは常にCPUレジスタの状態を完全に保存しなければならないというデメリットもある。

### 協調的マルチタスク

協調的マルチタスクでは、実行中のタスクを任意のタイミングで強制的に停止させるのではなく、各タスクが自発的にCPUの制御を放棄するまで実行させる。これによって、例えばI/O操作を待つ必要がある場合など、都合の良いタイミングでタスクを一時停止することができる。

協調的マルチタスクは主に言語レベルで使われることが多い。具体的には、_子ルーチン_や_async/await_などの形で登場する。これは、プログラマやコンパイラがプログラムに_yield_操作を挿入することで、CPUの制御を放棄し、他のタスクを実行させるというものである。

協調性マルチタスクは非同期I/Oと組み合わせるのが一般的である。非同期I/Oでは、操作が終了するまで待って、その間に他のタスクが実行できないようにする代わりに、操作がまだ終了していない場合は"not ready"というステータスを返す。この場合、待機中のタスクはyieldを実行して他のタスクを実行させることができる。

#### 状態の保存

タスクは自分で一時停止のポイントを決めるので、OSがタスクの状態を保存しなくて良くなる。一方で、自分が停止する直前に、継続するのに必要になる状態だけを保存することができ、結果としてパフォーマンスが向上する場合が多い。

言語でサポートされている協調タスクの実装では、一時停止する前にコールスタックの必要な部分をバックアップできることが多い。例えばRustのasync/awaitの実装では、まだ必要な全てのローカル変数を、自動的に生成された構造体に格納している。一時停止の前にコールスタックの関連部分をバックアップすることで、全てのタスクが単一のコールスタックを共有でき、タスクごとのメモリ消費量が大幅に少なくなる。これによってメモリ不足に陥ることなく、ほぼ任意の数の協調タスクを作成することができる。

#### 議論

協調的マルチタスクの欠点は、非協力的なタスクが無制限の時間実行できる可能性があることである。そのため、悪意のあるタスクやバグのあるタスクが他のタスクの実行を様食べ、システム全体の速度を低下させたり、ブロックしたりすることがある。このような理由から、協調的マルチタスクは全てのタスクが協調することが分かっている場合のみ使用する必要がある。反例としては、任意のユーザーレベルプログラムの協調にOSを依存させるのは非推奨となる。

一方で、協調的マルチタスクは、パフォーマンスやメモリの面で非常に優れているため、非同期処理を組み合わせてプログラム内で使用するのには適した手法となる。OSのカーネルは非同期のハードウェアとやりとりするプログラムであり、パフォーマンスが非常に重要となるため、協調的マルチタスクは同時実行の実装に適したアプローチであると言える。

## RustのAsync/Await

Rust言語は、async/awaitという形で協調的マルチタスクのファーストクラスのサポートを提供している。

### Future

futureは、まだ利用できない可能性のある値を表す。Rustでは`Future`というトレイトで表され、次のようになる。

```rust
pub trait Future {
    type Output;
    fn poll(self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output>;
}
```

関連型`Output`は非同期値の型を指定する。`poll`メソッドではその値がすでに利用可能かどうかをチェックすることができる。このメソッドは以下のような`Poll`列挙体を返す。

```rust
pub enum Poll<T> {
    Ready(T),
    Pending,
}
```

値がすでに利用可能ながあい、その値は`Ready`variantにラップされて返される。それ以外の場合は`Pending`variantが返され、呼び出し側に値がまだ利用できないことを知らせる。

### Async/Awaitパターン

async/awaitの背後にある考え方は、プログラマに見た目は通常の同期コードのように見えるが、コンパイラによって非同期コードに変換されるコードを書かせることである。これは`async, await`という二つのキーワードに基づいて動作する。`async`は関数のシグネチャの中で使用することができ、同期関数をfutureの値を返す非同期関数に変えることができる。

### Executor, Waker

単一のfutureであれば、ループを使って手動で各futureを待つことができる。しかしこの方法は効率が悪く、多数のfutureを作成するプログラムでは実用的ではない。これに対して、システム内の全てのfutureが終了するまでポーリングする責任を負う、グローバルなexecutorを定義して対応することができる。

Executorによって全てのfutureを中央集権的に管理することの大きな利点は、あるfutureが`Poll::Pending`を返すたびに、executorが別にfutureに切り替えられることである。これによって非同期の処理が並行して実行され、CPUをずっと忙しく使うことができる。futureを何度もポーリングすることによるオーバーヘッドを避けるために、executorsは通常、Rustのfutureがサポートする`waker` APIを利用する。

`waker` APIの背景にある考え方は、特別な`Waker`形が`Context`型にラップされて、`poll`の各呼び出しに渡されるというものである。この`Waker`型はexecutorによって作成され、非同期タスクがその（部分的な）完了を知らせるために使用することができる。結果として、executorは以前に`Poll::Pending`を返したfutureに対して、対応するwakerから通知されるまでの間`poll`を呼び出す必要がなくなる。

## まとめ

async/awaitを使うことで、カーネルで基本的な協調的マルチタスクをサポートできるようになった。協調的マルチタスクは非常に効率的だが、ここのタスクが長く実行しすぎる場合、他のタスクの実行が妨げられ、遅延の問題が発生する。このため、カーネルに非協調的マルチタスクのサポートを追加することは理にかなっていると言える。

非協調的マルチタスクの最も一般的な形態としてはスレッドが挙げられる。スレッドは長時間実行されるタスクの問題を解決するだけでなく、将来的に複数のCPUコアを利用したり、信頼できないユーザープログラムを実行したりするための準備にもなる。

---

個人学習用のメモ。オリジナルのブログ投稿は[phil-opp/blog_osにてCC-BY-NC](https://github.com/phil-opp/blog_os/tree/main/blog/content#license)で公開されている。
